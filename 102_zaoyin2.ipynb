{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Environment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "try:\n",
    "    import transformers\n",
    "except:\n",
    "    !pip install transformers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import types\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.12.1+cpu'"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "'4.21.2'"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "batch_size = 32\n",
    "n_epochs = 10\n",
    "\n",
    "noise_ratio = 0.15\n",
    "\n",
    "log_after_step = 50\n",
    "\n",
    "valid_after_step = 200\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "test_mode = True\n",
    "if test_mode:\n",
    "    n_epochs = 1000\n",
    "    data_length = 1\n",
    "    batch_size = 1\n",
    "    log_after_step = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gdown' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!gdown '1dC09i57lobL91lEbpebDuUBS0fGz-LAk' --folder --output data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "class CSCDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CSCDataset, self).__init__()\n",
    "        with open(\"data/trainall.times2.pkl\", mode='br') as f:\n",
    "            train_data = pickle.load(f)\n",
    "\n",
    "        self.train_data = train_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src = self.train_data[index]['src']\n",
    "        tgt = self.train_data[index]['tgt']\n",
    "        return src, tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        if test_mode:\n",
    "            return data_length\n",
    "        return len(self.train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "train_data = CSCDataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "('纽约早盘作为基准的低硫轻油，五月份交割价攀升一点三四美元，来到每桶二十八点二五美元，而上周五曾下挫一豪元以上。',\n '纽约早盘作为基准的低硫轻油，五月份交割价攀升一点三四美元，来到每桶二十八点二五美元，而上周五曾下挫一美元以上。')"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    src, tgt = zip(*batch)\n",
    "    src, tgt = list(src), list(tgt)\n",
    "\n",
    "    # src = tokenizer(src, padding='max_length', max_length=max_length, return_tensors='pt', truncation=True)\n",
    "    inputs = tokenizer(tgt, padding='max_length', max_length=max_length, return_tensors='pt', truncation=True)\n",
    "\n",
    "    input_ids_with_noise = []\n",
    "    noise = torch.zeros(batch_size, max_length, 768)\n",
    "    targets = torch.zeros(len(batch), max_length)\n",
    "    for i, indices in enumerate(inputs['input_ids']):\n",
    "        sentence_len = len(indices[indices != 0]) - 1\n",
    "        noise_len = math.floor(sentence_len * noise_ratio)\n",
    "        noise_indices = random.sample(range(1, sentence_len), noise_len)\n",
    "        for j, index in enumerate(noise_indices):\n",
    "            noise[i][index] = torch.rand(768)\n",
    "\n",
    "        input_ids_with_noise.append(indices)\n",
    "\n",
    "        targets[i][noise_indices] = 1\n",
    "\n",
    "    inputs['input_ids'] = torch.stack(input_ids_with_noise)\n",
    "\n",
    "    return inputs, targets, noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "inputs, targets, noise = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "'[CLS]纽约早盘作为基准的低硫轻油，五月份交割价攀升一点三四美元，来到每桶二十八点二五美元，而上周五曾下挫一美元以上。[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "for i, token in enumerate(tokenizer.convert_ids_to_tokens(range(0, len(tokenizer)))):\n",
    "    vocab[i] = token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('vocab.json', 'w', encoding='utf-8') as file:\n",
    "    file.write(json.dumps(vocab, ensure_ascii=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "from typing import Optional, List, Union, Tuple\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPoolingAndCrossAttentions\n",
    "\n",
    "\n",
    "def get_embeddings(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "):\n",
    "    r\"\"\"\n",
    "    encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
    "        Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n",
    "        the model is configured as a decoder.\n",
    "    encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "        Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n",
    "        the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
    "\n",
    "        - 1 for tokens that are **not masked**,\n",
    "        - 0 for tokens that are **masked**.\n",
    "    past_key_values (`tuple(tuple(torch.FloatTensor))` of length `config.n_layers` with each tuple having 4 tensors of shape `(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n",
    "        Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n",
    "\n",
    "        If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
    "        don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
    "        `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
    "    use_cache (`bool`, *optional*):\n",
    "        If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
    "        `past_key_values`).\n",
    "    \"\"\"\n",
    "    output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
    "    output_hidden_states = (\n",
    "        output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
    "    )\n",
    "    return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "    if self.config.is_decoder:\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "    else:\n",
    "        use_cache = False\n",
    "\n",
    "    if input_ids is not None and inputs_embeds is not None:\n",
    "        raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
    "    elif input_ids is not None:\n",
    "        input_shape = input_ids.size()\n",
    "    elif inputs_embeds is not None:\n",
    "        input_shape = inputs_embeds.size()[:-1]\n",
    "    else:\n",
    "        raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
    "\n",
    "    batch_size, seq_length = input_shape\n",
    "    device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
    "\n",
    "    # past_key_values_length\n",
    "    past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
    "\n",
    "    if attention_mask is None:\n",
    "        attention_mask = torch.ones(((batch_size, seq_length + past_key_values_length)), device=device)\n",
    "\n",
    "    if token_type_ids is None:\n",
    "        if hasattr(self.embeddings, \"token_type_ids\"):\n",
    "            buffered_token_type_ids = self.embeddings.token_type_ids[:, :seq_length]\n",
    "            buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)\n",
    "            token_type_ids = buffered_token_type_ids_expanded\n",
    "        else:\n",
    "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
    "\n",
    "    # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "    # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "    extended_attention_mask: torch.Tensor = self.get_extended_attention_mask(attention_mask, input_shape)\n",
    "\n",
    "    # If a 2D or 3D attention mask is provided for the cross-attention\n",
    "    # we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]\n",
    "    if self.config.is_decoder and encoder_hidden_states is not None:\n",
    "        encoder_batch_size, encoder_sequence_length, _ = encoder_hidden_states.size()\n",
    "        encoder_hidden_shape = (encoder_batch_size, encoder_sequence_length)\n",
    "        if encoder_attention_mask is None:\n",
    "            encoder_attention_mask = torch.ones(encoder_hidden_shape, device=device)\n",
    "        encoder_extended_attention_mask = self.invert_attention_mask(encoder_attention_mask)\n",
    "    else:\n",
    "        encoder_extended_attention_mask = None\n",
    "\n",
    "    # Prepare head mask if needed\n",
    "    # 1.0 in head_mask indicate we keep the head\n",
    "    # attention_probs has shape bsz x n_heads x N x N\n",
    "    # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "    # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "    head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)\n",
    "\n",
    "    embedding_output = self.embeddings(\n",
    "        input_ids=input_ids,\n",
    "        position_ids=position_ids,\n",
    "        token_type_ids=token_type_ids,\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        past_key_values_length=past_key_values_length,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"embedding_output\": embedding_output,\n",
    "        \"extended_attention_mask\": extended_attention_mask,\n",
    "        \"encoder_extended_attention_mask\": encoder_extended_attention_mask,\n",
    "        \"output_attentions\": output_attentions,\n",
    "        \"output_hidden_states\": output_hidden_states,\n",
    "        \"return_dict\": return_dict,\n",
    "        \"use_cache\": use_cache,\n",
    "        \"head_mask\": head_mask\n",
    "    }\n",
    "\n",
    "\n",
    "def post_forward(\n",
    "        self,\n",
    "        embedding_output,\n",
    "        extended_attention_mask,\n",
    "        encoder_extended_attention_mask,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    ") -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n",
    "    encoder_outputs = self.encoder(\n",
    "        embedding_output,\n",
    "        attention_mask=extended_attention_mask,\n",
    "        head_mask=head_mask,\n",
    "        encoder_hidden_states=encoder_hidden_states,\n",
    "        encoder_attention_mask=encoder_extended_attention_mask,\n",
    "        past_key_values=past_key_values,\n",
    "        use_cache=use_cache,\n",
    "        output_attentions=output_attentions,\n",
    "        output_hidden_states=output_hidden_states,\n",
    "        return_dict=return_dict,\n",
    "    )\n",
    "    sequence_output = encoder_outputs[0]\n",
    "    pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\n",
    "\n",
    "    if not return_dict:\n",
    "        return (sequence_output, pooled_output) + encoder_outputs[1:]\n",
    "\n",
    "    return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "        last_hidden_state=sequence_output,\n",
    "        pooler_output=pooled_output,\n",
    "        past_key_values=encoder_outputs.past_key_values,\n",
    "        hidden_states=encoder_outputs.hidden_states,\n",
    "        attentions=encoder_outputs.attentions,\n",
    "        cross_attentions=encoder_outputs.cross_attentions,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "bert.get_embeddings = types.MethodType(get_embeddings, bert)\n",
    "bert.post_forward = types.MethodType(post_forward, bert)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2529,  0.4439,  0.2850,  ..., -0.3361,  0.6868,  0.3597],\n         [-0.0817,  0.6666,  0.2779,  ..., -0.0320, -0.8320,  0.1756],\n         [-0.2023,  0.3854,  0.0892,  ...,  0.3342, -0.7750,  0.0900],\n         ...,\n         [ 0.3719, -0.0936, -0.4047,  ..., -0.1952,  0.3661,  0.2387],\n         [ 0.3607, -0.2736, -0.4350,  ..., -0.3174,  0.3545,  0.2572],\n         [ 0.3288, -0.5309, -0.1682,  ...,  0.1320,  0.2335,  0.0326]]],\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9679,  0.8660,  0.9613,  0.3479, -0.1692, -0.6037, -0.0633,  0.6258,\n          0.6686, -0.9294,  0.9961,  0.9976,  0.4176, -0.8774,  0.6814, -0.9524,\n          0.1755,  0.4708, -0.4872, -0.4379,  0.8697, -0.2062, -0.7883,  0.0814,\n          0.7156,  0.5902,  0.6876,  0.3140, -0.9910,  0.9262,  0.9062,  0.9598,\n          0.3435, -0.9885, -0.9888, -0.3147, -0.6561,  0.7444,  0.9299, -0.9882,\n         -0.8274, -0.5157, -0.1005, -0.9042, -0.5402,  0.5983, -0.9936, -0.8084,\n          0.2120,  0.6657, -0.1519, -0.8455,  0.9576, -0.8153,  0.3762,  0.8354,\n         -0.6658,  0.7173,  0.9872,  0.3969,  0.9588, -0.7038, -0.3718, -0.9173,\n          0.7345, -0.9645, -0.9722,  0.8110,  0.3995,  0.9959, -0.5464,  0.7395,\n          0.9918, -0.6535, -0.9780,  0.9949, -0.6230,  0.7593, -0.9959, -0.4178,\n          0.9887,  0.3376, -0.9821, -0.9804, -0.9147, -0.9142, -0.1755,  0.8989,\n          0.7777,  0.4318,  0.9717, -0.9098, -0.9967,  0.8950, -0.9443,  0.4989,\n         -0.8029,  0.9823,  0.1707, -0.9227, -0.1906,  0.7428, -0.9964, -0.9952,\n         -0.3346,  0.9370,  0.2765, -0.9625,  0.9866,  0.1500, -0.9944, -0.3670,\n         -0.9940,  0.5216, -0.5015,  0.9871,  0.8006,  0.8825,  0.2835, -0.9889,\n          0.9047,  0.1057, -0.4894, -0.8780,  0.5820,  0.9832,  0.9648, -0.0964,\n          0.9820,  0.9921,  0.6184,  0.9800, -0.9839,  0.4875,  0.2804, -0.9331,\n          0.3253, -0.0143,  0.9914,  0.9767,  0.5216, -0.2328,  0.9946, -0.8890,\n          0.9786, -0.9894,  0.9109, -0.9933,  0.7690,  0.2554,  0.0778,  0.9981,\n          0.8665,  0.9884, -0.9462, -0.6358,  0.4129, -0.7476,  0.1736, -0.9794,\n         -0.0972, -0.2634, -0.7746,  0.5744, -0.9862,  0.9462, -0.7076,  0.9867,\n          0.8383,  0.9450, -0.9642, -0.9728,  0.3498, -0.9472, -0.3947,  0.8142,\n         -0.7154,  0.9891,  0.2149, -0.4072, -0.0031, -0.6431, -0.7616,  0.8620,\n         -0.0282,  0.2526,  0.4186, -0.1777, -0.4861, -0.9669, -0.8676,  0.8043,\n          0.7889,  0.0483,  0.8863,  0.5895,  0.0783, -0.9627, -0.9982, -0.9362,\n          0.9946, -0.6194, -0.7741,  0.7108, -0.9431, -0.2387, -0.7089,  0.8990,\n         -0.3987, -0.9939,  0.1102,  0.2707, -0.9476,  0.2693,  0.9736,  0.3923,\n         -0.9892,  0.3362,  0.8106, -0.6634,  0.9272, -0.6940, -0.9095,  0.8646,\n          0.3931,  0.9838,  0.9245,  0.9889,  0.9922,  0.4244, -0.1649,  0.9929,\n          0.7322, -0.9953,  0.2544, -0.8729,  0.7595,  0.9849, -0.8753,  0.8668,\n          0.9952, -0.2662,  0.9952, -0.5754, -0.8163, -0.9604,  0.9923,  0.7493,\n          0.9943, -0.9047, -0.4165, -0.1634,  0.1725, -0.9917, -0.6881,  0.4361,\n          0.9557,  0.8160, -0.6776, -0.7603, -0.8790, -0.9216,  0.9890, -0.8146,\n         -0.4629,  0.6365, -0.2898, -0.3174,  0.3827, -0.8679, -0.7572, -0.6804,\n         -0.9967, -0.9574, -0.9866,  0.6604, -0.8541, -0.9974,  0.3866,  0.9883,\n          0.8037, -0.9939,  0.9566,  0.8273,  0.9960,  0.7172,  0.9424, -0.9980,\n          0.9966, -0.9618,  0.9705, -0.8919, -0.9871,  0.0576,  0.9168,  0.8663,\n         -0.9905,  0.8389, -0.9684,  0.8444,  0.4792,  0.7644, -0.9000, -0.6843,\n         -0.7225, -0.9648,  0.7235, -0.7793, -0.7119,  0.9257,  0.9881, -0.9416,\n          0.9966,  0.9729,  0.9987, -0.3093, -0.8175,  0.8180, -0.8284,  0.2453,\n          0.5066,  0.4336,  0.9461,  0.4863,  0.7185, -0.9732,  0.9404,  0.6088,\n          0.9040,  0.2223, -0.7744,  0.7308,  0.9960, -0.9501,  0.8977, -0.8822,\n          0.8349, -0.2866,  0.9762, -0.3247,  0.5829, -0.2335,  0.9689, -0.9851,\n          0.8858, -0.9905,  0.9529, -0.8775,  0.7223, -0.9784, -0.9131,  0.9703,\n          0.3094,  0.8229,  0.7448, -0.1414,  0.6884,  0.6956,  0.6197,  0.9662,\n          0.8747,  0.9926, -0.9974, -0.5733, -0.3320, -0.9653, -0.3694, -0.9945,\n          0.0289, -0.9091, -0.5214,  0.3833, -0.8207, -0.6971, -0.8850, -0.0470,\n         -0.5015,  0.5115, -0.2313,  0.4611, -0.3032, -0.9314, -0.3967, -0.9948,\n         -0.8535, -0.0467,  0.9844, -0.9948,  0.9605, -0.9888,  0.0277,  0.2942,\n          0.4324,  0.2662,  0.3076, -0.9152,  0.9866,  0.6470,  0.9950,  0.9566,\n          0.8956, -0.3792, -0.8779, -0.9029, -0.9738, -0.9959, -0.8642, -0.6671,\n         -0.0587, -0.9711, -0.5103,  0.6084,  0.9787,  0.9875, -0.9834, -0.0560,\n         -0.9778,  0.4693,  0.9631,  0.4859, -0.6976, -0.3912, -0.1844,  0.9590,\n         -0.8797, -0.6946,  0.4687, -0.3609,  0.8575, -0.9133,  0.2121,  0.9936,\n         -0.0431, -0.9893, -0.8145, -0.2735, -0.0894, -0.6934,  0.6233,  0.9892,\n         -0.9956, -0.9076, -0.8706,  0.4086,  0.8062,  0.8270,  0.8376,  0.7048,\n          0.9211, -0.7422, -0.7956,  0.9109,  0.0035, -0.9546,  0.7844, -0.9067,\n          0.4883, -0.9847,  0.9606, -0.2839,  0.9877,  0.4747, -0.1055, -0.0567,\n         -0.5728,  0.9640,  0.9895,  0.3442,  0.7339, -0.8669, -0.9865, -0.9461,\n         -0.2725,  0.2193, -0.5860, -0.9463,  0.5649, -0.7365,  0.9973,  0.9855,\n          0.9952,  0.6643, -0.9601,  0.9727, -0.5765,  0.7032,  0.0669, -0.9867,\n         -0.8462, -0.7732,  0.6028,  0.3311, -0.2254,  0.0557,  0.0544, -0.1430,\n         -0.9880, -0.9356, -0.6220,  0.9765,  0.9948, -0.6419,  0.2296, -0.8643,\n          0.0724,  0.0052,  0.9594,  0.8767, -0.6244, -0.5453, -0.4223,  0.4304,\n          0.9642,  0.9269, -0.3999, -0.9830,  0.9322,  0.8787,  0.5353, -0.3977,\n          0.6778,  0.8703,  0.9932,  0.7540,  0.9553, -0.9572,  0.7358,  0.9799,\n          0.9927,  0.8693,  0.1233, -0.8046,  0.4081,  0.3856,  0.7629,  0.6421,\n          0.3096, -0.6232,  0.9892,  0.5993,  0.9972,  0.9046,  0.3893,  0.7898,\n          0.4788, -0.5517,  0.9695,  0.7414,  0.3433,  0.7292,  0.9541, -0.9696,\n         -0.5094, -0.9899,  0.9938,  0.7861,  0.7691, -0.9882,  0.9245,  0.5016,\n          0.4977,  0.9248,  0.6846, -0.9535,  0.4342, -0.7266,  0.4707,  0.1354,\n          0.9145, -0.8418,  0.9601, -0.9463,  0.3010,  0.9918,  0.5719,  0.9443,\n          0.3722, -0.7625,  0.3325, -0.5471, -0.9367, -0.8202,  0.9328,  0.8225,\n         -0.5283, -0.4824, -0.1621, -0.5028,  0.9770, -0.9805,  0.9102, -0.6218,\n          0.9654, -0.8981, -0.9687,  0.3592,  0.6650, -0.7408,  0.1562,  0.9868,\n         -0.6118, -0.0448, -0.2548, -0.6108, -0.8574, -0.8962, -0.3470, -0.8273,\n         -0.2921, -0.3248,  0.6918, -0.8105, -0.9223,  0.9801, -0.9595, -0.8382,\n          0.9934, -0.0233, -0.9802,  0.7246, -0.8330, -0.3172,  0.1835, -0.7182,\n          0.3458, -0.9989, -0.3703,  0.9894, -0.9943, -0.4119, -0.7401, -0.5359,\n          0.1039, -0.1101,  0.8815, -0.2656,  0.1894, -0.3996,  0.9312, -0.7658,\n          0.3462, -0.9409,  0.8968,  0.6491, -0.9962, -0.9846, -0.9528,  0.9939,\n          0.9212,  0.9868, -0.7929,  0.0217,  0.6420,  0.9425, -0.9818,  0.7068,\n         -0.4548,  0.8159, -0.6750, -0.9122, -0.2918, -0.9873, -0.4314,  0.0901,\n          0.8781, -0.0697,  0.9922,  0.8906, -0.9478, -0.6844, -0.9930, -0.9708,\n          0.9736,  0.6782,  0.9028, -0.4686, -0.6040,  0.9779,  0.8434, -0.1475,\n         -0.9849, -0.9888, -0.9043,  0.8248, -0.7053, -0.9660,  0.9352,  0.9965,\n          0.4735, -0.9838, -0.9299,  0.9967,  0.9467,  0.9992, -0.9486,  0.9713,\n         -0.5282,  0.8538, -0.5561,  0.9913, -0.9624,  0.9934,  0.9918,  0.2500,\n          0.8612, -0.9690, -0.6548, -0.9227,  0.5238,  0.4414, -0.2463, -0.8689,\n         -0.3682,  0.9823, -0.9121,  0.9921,  0.7955, -0.5335,  0.9497,  0.3351,\n          0.8349, -0.5400, -0.9949,  0.4020,  0.9229,  0.8693,  0.9918,  0.9137,\n          0.9198, -0.9368, -0.9941, -0.1615, -0.4630, -0.0086, -0.9706,  0.9447,\n          0.9908, -0.9936, -0.0980, -0.3543,  0.8844,  0.7552,  0.1116,  0.1550,\n          0.8191,  0.3270,  0.9407, -0.9922, -0.6082, -0.6685, -0.4518,  0.7745,\n         -0.7930,  0.9887, -0.9434,  0.9906, -0.7223,  0.4638,  0.9422,  0.8805,\n         -0.7446,  0.9939,  0.5282, -0.6558,  0.3547, -0.8082, -0.8090,  0.0312]],\n       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_outputs = bert.get_embeddings(**inputs)\n",
    "bert.post_forward(**embeddings_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "class CSCModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CSCModel, self).__init__()\n",
    "\n",
    "        self.semantic_encoder = bert\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, noise=None, factor=1):\n",
    "        embeddings_outputs = self.semantic_encoder.get_embeddings(**inputs)\n",
    "\n",
    "        # old_embeddings = embeddings_outputs['embedding_output'].clone()\n",
    "\n",
    "        # if noise is not None:\n",
    "        #     embeddings_outputs['embedding_output'] = self._add_noise(embeddings_outputs['embedding_output'], noise)\n",
    "\n",
    "        outputs = self.semantic_encoder.post_forward(**embeddings_outputs)\n",
    "        outputs = outputs.last_hidden_state\n",
    "\n",
    "        if noise is not None:\n",
    "            # 将噪音加载bert后\n",
    "            outputs = outputs + noise * factor\n",
    "\n",
    "        return self.output_layer(outputs).squeeze(2)\n",
    "\n",
    "    def _add_noise(self, embeddings, noise):\n",
    "        return embeddings + noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "model = CSCModel()\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5665, 0.5359, 0.5386, 0.5283, 0.5565, 0.5202, 0.4897, 0.5335, 0.5094,\n         0.5146, 0.5254, 0.5342, 0.5416, 0.5206, 0.5596, 0.5899, 0.5513, 0.5106,\n         0.5380, 0.5558, 0.5359, 0.5704, 0.5711, 0.5259, 0.5203, 0.5388, 0.5168,\n         0.5161, 0.4874, 0.5813, 0.5706, 0.4736, 0.5599, 0.4991, 0.5599, 0.5279,\n         0.5520, 0.5002, 0.5317, 0.5117, 0.5314, 0.5011, 0.5675, 0.4650, 0.4737,\n         0.5203, 0.5411, 0.5274, 0.5303, 0.5907, 0.5114, 0.5229, 0.5057, 0.4655,\n         0.4850, 0.5142, 0.5665, 0.5036, 0.4982, 0.4964, 0.4959, 0.5248, 0.5244,\n         0.5319, 0.5327, 0.5270, 0.5317, 0.5236, 0.5190, 0.5179, 0.5249, 0.5128,\n         0.5273, 0.5151, 0.5036, 0.5031, 0.5088, 0.5060, 0.5119, 0.5178, 0.5247,\n         0.5304, 0.5331, 0.5246, 0.5395, 0.5199, 0.5190, 0.5137, 0.5255, 0.5258,\n         0.5182, 0.5213, 0.5288, 0.5400, 0.5453, 0.5384, 0.5413, 0.5353, 0.5311,\n         0.5304, 0.5285, 0.5356, 0.5469, 0.5219, 0.5203, 0.5162, 0.5283, 0.5303,\n         0.5347, 0.5271, 0.5232, 0.5251, 0.5336, 0.5284, 0.5187, 0.5423, 0.5127,\n         0.5408, 0.5134, 0.5264, 0.5065, 0.5041, 0.4955, 0.5070, 0.5093, 0.5255,\n         0.5223, 0.5220]], grad_fn=<SqueezeBackward1>)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs.to(device), noise.to(device))\n",
    "outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    segments = []\n",
    "    last_index = 0\n",
    "    for index in torch.where(outputs[0, 1:-1] >= 0.5)[0].tolist():\n",
    "        segments.append(text[last_index:index])\n",
    "        segments.append(\"\\033[1;31m\" + text[index] + \"\\033[0m\")\n",
    "        last_index = index + 1\n",
    "    segments.append(text[last_index:])\n",
    "\n",
    "    return ''.join(segments), (outputs[0, 1:-1] >= 0.5).int()\n",
    "\n",
    "\n",
    "def validation():\n",
    "    with open(\"data/test.sighan15.pkl\", mode='br') as f:\n",
    "        test_data = pickle.load(f)\n",
    "\n",
    "    total_num = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    total_recall_num = 0\n",
    "    total_recall_correct = 0\n",
    "\n",
    "    total_precision_num = 0\n",
    "    total_precision_correct = 0\n",
    "\n",
    "    prograss = tqdm(range(len(test_data)))\n",
    "    for i in prograss:\n",
    "        src, tgt = test_data[i]['src'], test_data[i]['tgt']\n",
    "\n",
    "        _, output = predict(src)\n",
    "        target = (torch.tensor(test_data[i]['src_idx']) != torch.tensor(test_data[i]['tgt_idx'])).int()[1:-1].to(device)\n",
    "\n",
    "        if len(output) != len(target):\n",
    "            print(\"第%d条数据异常，请检查\" % i)\n",
    "            break\n",
    "\n",
    "        total_num += 1\n",
    "        if (output != target).sum().item() == 0:\n",
    "            total_correct += 1\n",
    "\n",
    "        total_recall_correct += output[target == 1].sum().item()\n",
    "        total_recall_num += (target == 1).sum().item()\n",
    "\n",
    "        total_precision_num += (output == 1).sum().item()\n",
    "        total_precision_correct += (target[output == 1]).sum().item()\n",
    "\n",
    "        accuracy = total_correct / total_num\n",
    "        recall = total_recall_correct / (total_recall_num + 1e-9)\n",
    "        precision = total_precision_correct / (total_precision_num + 1e-9)\n",
    "\n",
    "        prograss.set_postfix({\n",
    "            'accuracy': accuracy,\n",
    "            'recall': recall,\n",
    "            'precision': precision\n",
    "        })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 953/1100 [01:27<00:13, 10.89it/s, accuracy=0.509, recall=0, precision=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-97-232479bfb929>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mvalidation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-96-4860996ba330>\u001B[0m in \u001B[0;36mvalidation\u001B[1;34m()\u001B[0m\n\u001B[0;32m     31\u001B[0m         \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'src'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tgt'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 33\u001B[1;33m         \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     34\u001B[0m         \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'src_idx'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tgt_idx'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-96-4860996ba330>\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'pt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0msegments\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-91-0d15da218c4a>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, inputs, noise)\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[1;31m#     embeddings_outputs['embedding_output'] = self._add_noise(embeddings_outputs['embedding_output'], noise)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msemantic_encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpost_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0membeddings_outputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlast_hidden_state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-88-322744e9a8da>\u001B[0m in \u001B[0;36mpost_forward\u001B[1;34m(self, embedding_output, extended_attention_mask, encoder_extended_attention_mask, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    137\u001B[0m         \u001B[0mreturn_dict\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbool\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPoolingAndCrossAttentions]:\n\u001B[1;32m--> 139\u001B[1;33m     encoder_outputs = self.encoder(\n\u001B[0m\u001B[0;32m    140\u001B[0m         \u001B[0membedding_output\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m         \u001B[0mattention_mask\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    605\u001B[0m                 )\n\u001B[0;32m    606\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 607\u001B[1;33m                 layer_outputs = layer_module(\n\u001B[0m\u001B[0;32m    608\u001B[0m                     \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m                     \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    491\u001B[0m         \u001B[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    492\u001B[0m         \u001B[0mself_attn_past_key_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpast_key_value\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mpast_key_value\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 493\u001B[1;33m         self_attention_outputs = self.attention(\n\u001B[0m\u001B[0;32m    494\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    495\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    421\u001B[0m         \u001B[0moutput_attentions\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mbool\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    422\u001B[0m     ) -> Tuple[torch.Tensor]:\n\u001B[1;32m--> 423\u001B[1;33m         self_outputs = self.self(\n\u001B[0m\u001B[0;32m    424\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    425\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    326\u001B[0m         \u001B[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 327\u001B[1;33m         \u001B[0mattention_scores\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmatmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_layer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey_layer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    328\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mposition_embedding_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"relative_key_query\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "validation()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "model = model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "criteria = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.output_layer.parameters(), lr=1e-4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 1, loss 0.74591, accuracy 0.1250, recall 0.8750\n",
      "Epoch 1, Step 2, loss 0.69944, accuracy 0.3594, recall 0.7500\n",
      "Epoch 2, Step 3, loss 0.66917, accuracy 0.7578, recall 0.6250\n",
      "Epoch 3, Step 4, loss 0.63116, accuracy 0.9219, recall 0.5000\n",
      "Epoch 4, Step 5, loss 0.59788, accuracy 0.9375, recall 0.1250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-104-24f058ae9ee2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriteria\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    394\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 396\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    171\u001B[0m     \u001B[1;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m     \u001B[1;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 173\u001B[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    174\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "total_loss = 0.\n",
    "total_correct = 0\n",
    "total_num = 0\n",
    "total_correct_wrong_char = 0\n",
    "total_wrong_char = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for inputs, targets, noise in train_loader:\n",
    "        inputs, targets, noise = inputs.to(device), targets.to(device), noise.to(device)\n",
    "        outputs = model(inputs, noise)\n",
    "        loss = criteria(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        total_loss += loss.detach().item()\n",
    "        total_correct += ((outputs >= 0.5).int() == targets.int()).sum().item()\n",
    "        total_num += len(targets.flatten())\n",
    "\n",
    "        # 统计成功预测错字的数量\n",
    "        total_correct_wrong_char += (outputs >= 0.5)[targets == 1].sum().item()\n",
    "        # 统计错字的数量\n",
    "        total_wrong_char += (targets == 1).sum().item()\n",
    "\n",
    "        if step % log_after_step == 0:\n",
    "            print(\"Epoch {}, Step {}, loss {:.5f}, accuracy {:.4f}, recall {:.4f}\".format(epoch, step,\n",
    "                                                                                          total_loss / log_after_step,\n",
    "                                                                                          total_correct / total_num,\n",
    "                                                                                          total_correct_wrong_char / total_wrong_char))\n",
    "            total_loss = 0.\n",
    "            total_correct = 0\n",
    "            total_num = 0\n",
    "            total_correct_wrong_char = 0\n",
    "            total_wrong_char = 0\n",
    "\n",
    "        if step % valid_after_step == 0:\n",
    "            model = model.eval()\n",
    "            validation()\n",
    "            model = model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model = torch.load('csc-model.pt', map_location='cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    segments = []\n",
    "    last_index = 0\n",
    "    for index in torch.where(outputs[0, 1:-1] >= 0.5)[0].tolist():\n",
    "        segments.append(text[last_index:index])\n",
    "        segments.append(\"\\033[1;31m\" + text[index] + \"\\033[0m\")\n",
    "        last_index = index + 1\n",
    "    segments.append(text[last_index:])\n",
    "\n",
    "    return ''.join(segments), (outputs[0, 1:-1] >= 0.5).int()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'get_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-33-7750347dae31>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"昨天下雨了你紫道吗，但是有些词确实太男了\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-32-d92c25dec240>\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'pt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0msegments\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-22-d5f880e44e62>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, inputs, noise)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0membeddings_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msemantic_encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_embeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[1;31m# old_embeddings = embeddings_outputs['embedding_output'].clone()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1205\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1206\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1207\u001B[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001B[0m\u001B[0;32m   1208\u001B[0m             type(self).__name__, name))\n\u001B[0;32m   1209\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'BertModel' object has no attribute 'get_embeddings'"
     ]
    }
   ],
   "source": [
    "text, output = predict(\"昨天下雨了你紫道吗，但是有些词确实太男了\")\n",
    "print(text)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-aa785adca3fc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtext\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "with open(\"data/test.sighan15.pkl\", mode='br') as f:\n",
    "    test_data = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'get_embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-36-efb36a3472b2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'src'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tgt'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m     \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m     \u001B[0mtarget\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'src_idx'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'tgt_idx'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-32-d92c25dec240>\u001B[0m in \u001B[0;36mpredict\u001B[1;34m(text)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'pt'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m     \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0msegments\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-22-d5f880e44e62>\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, inputs, noise)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0membeddings_outputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msemantic_encoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_embeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[1;31m# old_embeddings = embeddings_outputs['embedding_output'].clone()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1205\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1206\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mmodules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1207\u001B[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001B[0m\u001B[0;32m   1208\u001B[0m             type(self).__name__, name))\n\u001B[0;32m   1209\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'BertModel' object has no attribute 'get_embeddings'"
     ]
    }
   ],
   "source": [
    "total_num = 0\n",
    "total_correct = 0\n",
    "\n",
    "total_recall_num = 0\n",
    "total_recall_correct = 0\n",
    "\n",
    "total_precision_num = 0\n",
    "total_precision_correct = 0\n",
    "\n",
    "prograss = tqdm(range(len(test_data)))\n",
    "for i in prograss:\n",
    "    src, tgt = test_data[i]['src'], test_data[i]['tgt']\n",
    "\n",
    "    _, output = predict(src)\n",
    "    target = (torch.tensor(test_data[i]['src_idx']) != torch.tensor(test_data[i]['tgt_idx'])).int()[1:-1].to(device)\n",
    "\n",
    "    if len(output) != len(target):\n",
    "        print(\"第%d条数据异常\" % i)\n",
    "\n",
    "    total_num += 1\n",
    "    if (output != target).sum().item() == 0:\n",
    "        total_correct += 1\n",
    "\n",
    "    total_recall_correct += output[target == 1].sum().item()\n",
    "    total_recall_num += (target == 1).sum().item()\n",
    "\n",
    "    total_precision_num += (output == 1).sum().item()\n",
    "    total_precision_correct += (target[output == 1]).sum().item()\n",
    "\n",
    "    accuracy = total_correct / total_num\n",
    "    recall = total_recall_correct / (total_recall_num + 1e-9)\n",
    "    precision = total_precision_correct / (total_precision_num + 1e-9)\n",
    "\n",
    "    prograss.set_postfix({\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "inputs, targets, noise = next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1913,  0.4629,  0.1537,  ..., -0.2570,  0.6134,  0.2509],\n         [-0.2789,  0.4452,  0.5893,  ...,  0.0723, -0.6717,  0.3080],\n         [ 0.1223,  0.6099, -0.1760,  ...,  0.4076, -0.7872, -0.0595],\n         ...,\n         [ 0.4089,  0.0132, -0.3093,  ..., -0.1026,  0.2535, -0.0268],\n         [ 0.3961, -0.2212, -0.4009,  ..., -0.3125,  0.3070,  0.2665],\n         [-0.0680, -0.2509, -0.1265,  ...,  0.0023,  0.2936,  0.1970]]],\n       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9873,  0.9758,  0.9731,  0.2817,  0.1743, -0.5727, -0.3220,  0.4456,\n          0.8401, -0.9588,  0.9980,  0.9968, -0.0707, -0.9233,  0.8343, -0.9748,\n          0.0422, -0.0530, -0.0390, -0.5145,  0.9843, -0.5351, -0.8328,  0.1778,\n          0.6584,  0.7481,  0.7090,  0.0279, -0.9910,  0.9576,  0.8916,  0.9894,\n          0.4681, -0.9828, -0.9924, -0.3028, -0.4059,  0.6635,  0.8629, -0.9720,\n         -0.7661, -0.6973, -0.1980, -0.9103, -0.6571,  0.6058, -0.9964, -0.8358,\n          0.0386,  0.9153, -0.2722, -0.9136,  0.9306, -0.8138, -0.0214,  0.8854,\n         -0.7367,  0.7352,  0.9936,  0.6489,  0.9750, -0.7648, -0.0553, -0.9537,\n          0.8864, -0.9681, -0.9773,  0.8549,  0.8627,  0.9972, -0.4808,  0.7501,\n          0.9958, -0.7611, -0.9747,  0.9929, -0.5855,  0.6810, -0.9973, -0.2731,\n          0.9948,  0.5285, -0.9822, -0.9338, -0.8505, -0.9632, -0.4346,  0.9030,\n          0.7677,  0.6681,  0.9614, -0.9681, -0.9983,  0.9480, -0.9663,  0.1355,\n         -0.8195,  0.9944,  0.2816, -0.8949, -0.4038,  0.6615, -0.9946, -0.9942,\n         -0.3093,  0.9608,  0.1351, -0.9804,  0.9799,  0.0350, -0.9975, -0.4102,\n         -0.9947,  0.2524, -0.6479,  0.9933,  0.8080,  0.9012,  0.8239, -0.9873,\n          0.8657,  0.0162, -0.6335, -0.8239,  0.8236,  0.9921,  0.9758, -0.3836,\n          0.9785,  0.9964,  0.6798,  0.9657, -0.9859,  0.5030,  0.3318, -0.9234,\n          0.1441, -0.0325,  0.9970,  0.9821,  0.6047, -0.3361,  0.9928, -0.8546,\n          0.9914, -0.9932,  0.8920, -0.9972,  0.7059,  0.7831,  0.1095,  0.9992,\n          0.8463,  0.9879, -0.8854, -0.8101,  0.4300, -0.5387,  0.3010, -0.9920,\n         -0.0580, -0.3965, -0.6908,  0.5704, -0.9915,  0.9716, -0.6780,  0.9924,\n          0.8533,  0.9060, -0.9820, -0.9734,  0.4501, -0.9569,  0.1757,  0.8683,\n         -0.3941,  0.9946,  0.0039, -0.6891,  0.2623, -0.5851, -0.9522,  0.8800,\n          0.1043,  0.0932,  0.3527, -0.1003, -0.5595, -0.9606, -0.8459,  0.9494,\n          0.7604,  0.3595,  0.9493,  0.6177, -0.0524, -0.9081, -0.9991, -0.8967,\n          0.9950, -0.6769, -0.8694,  0.4664, -0.9675, -0.1327, -0.6566,  0.8511,\n         -0.6633, -0.9970,  0.4586,  0.2439, -0.9733,  0.4172,  0.9692,  0.1982,\n         -0.9912,  0.0889,  0.8406, -0.5111,  0.9348, -0.5093, -0.9507,  0.9265,\n         -0.0701,  0.9757,  0.9043,  0.9942,  0.9859,  0.5048,  0.2055,  0.9948,\n          0.7168, -0.9983,  0.3180, -0.9543,  0.7910,  0.9911, -0.7810,  0.8881,\n          0.9976, -0.2033,  0.9969, -0.6255, -0.9424, -0.9702,  0.9958,  0.8017,\n          0.9969, -0.9351, -0.8327, -0.1335,  0.1339, -0.9968, -0.9103,  0.5333,\n          0.9616,  0.9117, -0.7064, -0.9217, -0.8303, -0.9532,  0.9963, -0.8729,\n         -0.3240,  0.7166, -0.4633, -0.6054,  0.3730, -0.8341, -0.7464, -0.6546,\n         -0.9971, -0.9489, -0.9926,  0.8824, -0.9201, -0.9987,  0.1864,  0.9954,\n          0.6418, -0.9939,  0.9673,  0.9239,  0.9912,  0.6851,  0.9480, -0.9991,\n          0.9982, -0.9743,  0.9617, -0.8853, -0.9908,  0.1662,  0.9496,  0.8630,\n         -0.9874,  0.8741, -0.9767,  0.8813,  0.5525,  0.8652, -0.9183, -0.8040,\n         -0.7747, -0.9642,  0.8349, -0.8313, -0.8365,  0.9566,  0.9946, -0.9039,\n          0.9987,  0.9829,  0.9996, -0.3389, -0.9070,  0.8862, -0.7769, -0.1859,\n          0.2557,  0.6104,  0.9310,  0.4969,  0.7048, -0.9733,  0.9719,  0.6461,\n          0.7251,  0.3615, -0.8632,  0.7867,  0.9920, -0.9734,  0.9627, -0.9290,\n          0.8603, -0.3058,  0.9888,  0.1498,  0.4728, -0.3328,  0.9781, -0.9812,\n          0.9504, -0.9931,  0.9627, -0.8981,  0.4803, -0.9754, -0.8834,  0.9840,\n          0.5925,  0.4899,  0.8361, -0.0749,  0.8363,  0.5993,  0.7339,  0.9746,\n          0.9003,  0.9925, -0.9950, -0.4915, -0.5996, -0.9841, -0.5922, -0.9968,\n         -0.1383, -0.9360, -0.5409,  0.3437, -0.7551, -0.5228, -0.9065, -0.0997,\n         -0.6076,  0.2641, -0.4193,  0.4641, -0.3714, -0.9616, -0.7103, -0.9975,\n         -0.8905, -0.1890,  0.9873, -0.9943,  0.9726, -0.9953,  0.0518,  0.2875,\n          0.3962,  0.2825,  0.4850, -0.9646,  0.9880,  0.7669,  0.9976,  0.9841,\n          0.9698, -0.8373, -0.9494, -0.9127, -0.9676, -0.9978, -0.9169, -0.6968,\n         -0.1008, -0.9886, -0.4534,  0.6086,  0.9906,  0.9883, -0.9884, -0.4141,\n         -0.9788,  0.2575,  0.9602,  0.4864, -0.9337, -0.7125, -0.2526,  0.9846,\n         -0.8329, -0.6681,  0.4285, -0.4630,  0.8320, -0.9517,  0.1083,  0.9966,\n         -0.1119, -0.9944, -0.8655,  0.0111, -0.2257, -0.7102,  0.7200,  0.9936,\n         -0.9905, -0.8117, -0.9422,  0.5641,  0.8246,  0.7726,  0.8533,  0.8016,\n          0.9567, -0.5426, -0.7487,  0.9752, -0.0300, -0.9658,  0.7765, -0.9210,\n          0.4222, -0.9871,  0.9773, -0.2871,  0.9878,  0.4120, -0.2704, -0.2296,\n         -0.6654,  0.9690,  0.9948,  0.1832,  0.0851, -0.9049, -0.9832, -0.9439,\n         -0.4429,  0.1401, -0.5931, -0.9700,  0.4949, -0.8480,  0.9990,  0.9815,\n          0.9959,  0.7936, -0.9415,  0.9893, -0.6326,  0.6386, -0.1741, -0.9933,\n         -0.8138, -0.7167,  0.9480,  0.3400, -0.4344, -0.0672,  0.1969,  0.0400,\n         -0.9868, -0.8511, -0.5606,  0.9635,  0.9979, -0.9271,  0.5943, -0.8903,\n         -0.0320, -0.0707,  0.9596,  0.9095, -0.7689, -0.5475, -0.2938,  0.0598,\n          0.9127,  0.9446, -0.7860, -0.9598,  0.9626,  0.8506,  0.8671, -0.4615,\n          0.7468,  0.9023,  0.9958,  0.8822,  0.9843, -0.9176,  0.8499,  0.9921,\n          0.9906,  0.8485,  0.0389, -0.7324,  0.3864,  0.5938,  0.8628,  0.4990,\n         -0.0712, -0.7105,  0.9625,  0.9326,  0.9990,  0.8880,  0.5260,  0.7907,\n          0.3960, -0.2863,  0.9557,  0.8582,  0.3028,  0.9436,  0.9716, -0.9843,\n         -0.6117, -0.9955,  0.9972,  0.9082,  0.7600, -0.9951,  0.9757,  0.4746,\n          0.1834,  0.9758,  0.7322, -0.9740,  0.1444, -0.8002,  0.4858,  0.2250,\n          0.9321, -0.7750,  0.9829, -0.9808,  0.3082,  0.9949,  0.4034,  0.9893,\n          0.2685, -0.9402,  0.5958, -0.7770, -0.9617, -0.7065,  0.9073,  0.8491,\n         -0.4565, -0.6457, -0.0082, -0.8171,  0.9872, -0.9897,  0.9283, -0.7261,\n          0.9809, -0.8684, -0.9864,  0.2033,  0.7538, -0.6536, -0.1587,  0.9883,\n         -0.5311, -0.1861,  0.0211, -0.6841, -0.8707, -0.9376, -0.4147, -0.9687,\n         -0.1140,  0.0837,  0.6295, -0.8020, -0.9827,  0.9785, -0.9525, -0.8980,\n          0.9976,  0.1472, -0.9912,  0.8651, -0.8653, -0.0549,  0.4175, -0.6226,\n          0.4212, -0.9994, -0.1578,  0.9907, -0.9913, -0.2396, -0.6856, -0.5950,\n          0.2380,  0.4347,  0.8365, -0.4355,  0.3570,  0.2282,  0.9373, -0.7727,\n          0.5396, -0.9515,  0.6831,  0.4333, -0.9926, -0.9821, -0.9736,  0.9974,\n          0.9745,  0.9874, -0.9237, -0.0755,  0.7516,  0.9567, -0.9874,  0.3689,\n         -0.3322,  0.8022, -0.7263, -0.9725, -0.2465, -0.9919, -0.4914,  0.0852,\n          0.8787,  0.0295,  0.9963,  0.9637, -0.9848, -0.6614, -0.9945, -0.9864,\n          0.9830,  0.9209,  0.9218, -0.4626, -0.6748,  0.9785,  0.7018, -0.0587,\n         -0.9899, -0.9904, -0.9761,  0.8437, -0.7964, -0.9442,  0.9539,  0.9963,\n          0.4720, -0.9936, -0.9032,  0.9972,  0.9611,  0.9996, -0.9487,  0.9874,\n         -0.6667,  0.8932, -0.6889,  0.9973, -0.9801,  0.9959,  0.9973,  0.4499,\n          0.9379, -0.9705, -0.5013, -0.9480,  0.5253,  0.6167, -0.1452, -0.9116,\n         -0.3997,  0.9599, -0.9568,  0.9964,  0.7664, -0.5511,  0.9538,  0.3485,\n          0.8659, -0.3904, -0.9972,  0.2137,  0.8560,  0.8886,  0.9967,  0.9172,\n          0.9807, -0.9368, -0.9950, -0.3136, -0.5312, -0.0864, -0.9930,  0.9707,\n          0.9886, -0.9942, -0.2682, -0.3915,  0.8882,  0.9376,  0.3876,  0.1978,\n          0.9015,  0.4601,  0.9797, -0.9928, -0.3508, -0.7600, -0.5517,  0.9432,\n         -0.8659,  0.9901, -0.9776,  0.9910, -0.8903,  0.5524,  0.9308,  0.9301,\n         -0.8888,  0.9968,  0.2122, -0.8265,  0.6905, -0.8981, -0.8322, -0.1921]],\n       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_outputs = bert.get_embeddings(**inputs)\n",
    "bert.post_forward(**embeddings_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  #用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  #用来正常显示负号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "def token_embeddings_visualise(embeddings, text):\n",
    "    \"\"\"\n",
    "    将汉字文本embedding绘制成图像\n",
    "    :param embeddings: 文本embedding后的向量，例如Shape为(55, 768)为55个token，每个token维度为768。\n",
    "                       不要包含bos、eos和pad。embedding需要是numpy类型的\n",
    "    :param text: 汉字文本，例如 “张三是法外狂徒”。text的长度需要和上面的token数一致\n",
    "    \"\"\"\n",
    "    assert type(embeddings) is np.ndarray, \"embedding参数必须是numpy.ndarray类型\"\n",
    "    assert embeddings.shape[0] == len(text), \"embedding的token数与text不一致\"\n",
    "\n",
    "    # 1. 将词向量降维到2维度\n",
    "    pca = PCA(n_components=2)\n",
    "    embeddings = pca.fit_transform(embeddings)\n",
    "    # 2. 创建一个16x9大小的维度图像\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    # 3. 循环绘制文字\n",
    "    for i in range(len(embeddings)):\n",
    "        plt.text(embeddings[i][0], embeddings[i][1], text[i])\n",
    "\n",
    "    # 4. 设置坐标边界\n",
    "    plt.xlim(embeddings[:, 0].min() - 0.5, embeddings[:, 0].max() + 0.5)\n",
    "    plt.ylim(embeddings[:, 1].min() - 0.5, embeddings[:, 1].max() + 0.5)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "text = \"前天我吃了一大个火聋果\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "outputs = bert(**inputs).last_hidden_state[0, 1:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "embeddings = outputs.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无噪音，bert前\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x648 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"无噪音，bert前\")\n",
    "token_embeddings_visualise(embeddings, text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "embeddings = bert(**inputs)['last_hidden_state'][0][1:56].detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无噪音，bert编码后\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "embedding的token数与text不一致",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-143-6af70719ac1d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"无噪音，bert编码后\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtoken_embeddings_visualise\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m<ipython-input-113-4b916374558b>\u001B[0m in \u001B[0;36mtoken_embeddings_visualise\u001B[1;34m(embeddings, text)\u001B[0m\n\u001B[0;32m      7\u001B[0m     \"\"\"\n\u001B[0;32m      8\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"embedding参数必须是numpy.ndarray类型\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[1;32massert\u001B[0m \u001B[0membeddings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"embedding的token数与text不一致\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m     \u001B[1;31m# 1. 将词向量降维到2维度\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: embedding的token数与text不一致"
     ]
    }
   ],
   "source": [
    "print(\"无噪音，bert编码后\")\n",
    "token_embeddings_visualise(embeddings, text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有噪音, bert前\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x648 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6YAAAIGCAYAAABH6ZKxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABHCklEQVR4nO3deXwV1f3/8fdJ7k3CDmGHIqhsAgXEiyBrkCCrgqACAn6xVXGprSJiKRSsRYtVLNQqrYqo+EMroKgokgSIiIVCEDBsgsoeoCwxgIHc5Ob8/iBEAwmQ9WR5PR+P++jcmTMzn8HbeTzeOWfOGGutAAAAAABwJch1AQAAAACAso1gCgAAAABwimAKAAAAAHCKYAoAAAAAcIpgCgAAAABwimAKAAAAAHDK47qAc2rUqGEbNWrkugwAAAAAQCFYv379UWttzey2XVYwNcbUlrTAWtvVGFNF0ruSgiX9KGmotdafzT4eSd9nfCTpYWttfE7naNSokeLi4i6nHAAAAABACWOM2ZPTtksO5TXGVJP0pqQKGatGSHrBWnuTpEOS+uSwa2tJ71hrIzI+OYZSAAAAAEDZdTnPmAYkDZV0QpKstS9ba6MzttWU9L8c9usoaYAxZq0xZnZGDyoAAAAAAFlcMixaa09IkjEmy3pjzA2Sqllr1+Sw6zpJkdbag8aYtyT1k/TRece4T9J9knTFFVfkungAAAAAKIluuukmpaen57j9k08+UWhoaBFW5FaeejGNMeGSXpQ05CLNvrbWpmQsx0lqcn4Da+0rkl6RJJ/PZ/NSCwAAAACUNEePHtVXX32l6OhorV27VqmpqYqIiFBERIQ6duyooKCy9QKVXF+tMSZE0nxJE6y1OT68KmmuMaaNMSZY0iBJm/JWIgAAAACULiEhIZKkpKQkVa1a9YLtXq+3iCtyKy8x/NeS2kmaaIyJNcYMNca0MMZMPa/dU5LmStooabW1NiZ/pQIAAABA6bJ27Vq1atXKdRnOXXYwtdZGZPzvLGtttZ/Ntvtva+1Wa+2k89pvtta2ttb+0lo7sYDrBgAAAIASLSkpSf/5z3/UuXNnGWN06tQppaamui7LCWbKBQAAAAAH7r33Xv35z3+Wx+NRz549NXHiRH388ceuy3KCYAoAAAAADrz11lsKCwuTJHXp0kWff/65JKljx44uy3KCYAoAAAAARWzHjh3q06dPttu2bt2qQCCg4ODgIq7KHYIpAAAAABSxBg0aKDY2NtttHTt2lN/vV7ly5Yq2KIcIpgAAAABQxM4N283OmjVrirCS4qFsvbUVAAAAAIqB7N5dWpYRTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAACghJk5c6YaNGigxo0bZ/nUrl1bixYtcl1erhlrresaJEk+n8/GxcW5LgMAAAAAUAiMMeuttb7sttFjCgAAAABwimAKAAAAAHCKYAoAAAAAcIpgCgAAAAAlyKXmCbLWKi0trYiqKRge1wUAAAAAAC7fjBkzNGPGDHm93my3+/1+Pffccxo6dGgRV5Z3zMoLAAAAACh0zMoLAAAAACi2CKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimhcTv9+e4LTU1tQgrAQAAAIDizeO6gNLq8ccf15YtWyRJGzZs0LXXXpu5rUGDBpozZ46r0gAAAACgWCGYFpKZM2dmLvfq1UvR0dEOqwEAAACA4otgWkji4+P1u9/9TsYYbdq0SZGRkZKkDh066Omnn3ZcHQAAAAAUHwTTQtKqVSstW7ZMK1eu1JIlSzRt2jQdPHhQY8eOdV0aAAAAABQrBNNCYoyRJO3cuVNNmjSRJCUnJyssLMxlWQAAAABQ7DArbyHbsWNHlmAaGhrquCIAAAAAKF7oMS0EUVFRGj9+vDwej3bv3q1PP/1UYWFhSk5O1tGjR7Vu3TpNmTJFt9xyi+tSAQAAAMA5gmkh6NGjh+Li4uTxZP/Pm56eXsQVAQAAAEDxRTAtBF6v96Lbg4IYQQ0AAAAA55CQAAAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOXVYwNcbUNsZ88bPvs40xq40xky6x32W1Ky38fn+O21JTU4uwEgAAAAAoOTyXamCMqSbpTUkVMr4PlhRsrb3BGPO6MaaJtXZnNvtdVrvS5PHHH9eWLVskSRs2bNC1116bua1BgwaaM2eOq9IAAAAAoNi6ZDCVFJA0VNKHGd8jJL2XsRwlqYuk7ALnJdsZY+6TdJ8kXXHFFZdfdTE1c+bMzOVevXopOjraYTUAAAAAUDJcciivtfaEtTbpZ6sqSDqQsXxcUu0cdr1kO2vtK9Zan7XWV7NmzcuvupiKj4/XjTfeqJ49e2rDhg2KjIxUZGSkJk6c6Lo0AAAAACi2LqfH9HynJJXLWK6onMPt5bYrNVq1aqVly5Zp5cqVWrJkiaZNm6aDBw9q7NixrksDAAAAgGIrL2Fxvc4Oy5WkNpJ257NdqWGMkTFGO3fuVJMmTSRJycnJCgsLc1wZAAAAABRfeekxXSTpC2NMPUl9JXU0xrSQdKe1dtLF2uWz1hJjx44dGjBggKSzwTQ0NNRxRQAAAABQfBlrbe53OjtTby9JK621h/LbTpJ8Pp+Ni4vLdS3FRVRUlMaPHy+Px6Pdu3erTp06CgsLU3Jyso4ePaoGDRpoypQpuuWWW1yXCgAAAABFzhiz3lrry3ZbXoJpYSjpwTQ1NVXGGHk82XdCp6enS5KCgkr9o7YAAAAAcIGLBdO8DOVFNrxe70W3E0gBAAAAIHukJQAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBNMSxu/357gtNTW1CCsBAAAAgILhcV0Acufxxx/Xli1bJEkbNmzQtddem7mtQYMGmjNnjqvSAAAAACBPCKYlzMyZMzOXe/XqpejoaIfVAAAAAED+EUxLmPj4eP3ud7+TMUabNm1SZGSkJKlDhw56+umnHVcHAAAAALlHMC1hWrVqpWXLlmnlypVasmSJpk2bpoMHD2rs2LGuSwMAAACAPGHyo2Jm27Ztstbqm2++0cSJEy/YboyRMUY7d+5UkyZNJEnJyckKCwsr6lIBAAAAoEAQTIuZfv36KRAIqHr16lq3bl2O7Xbs2JElmIaGhhZViQAAAABQoBjKW4wEAgHVrVtXHo9HNWrUUHJycpbtUVFRGj9+vDwej3bv3q1PP/1UYWFhSk5O1tGjR7Vu3TpNmTJFt9xyi6MrAAAAAIDcI5gWIxs3btQvf/nLzO9er1fJyckqX768JKlHjx6Ki4uTx5P9f7b09PQiqRMAAAAAChJDeYuR2NhYde/ePfN7hw4dsgzn9Xq9OYZSSQoKClJQEP9JAQAAAJQspJhiwlqrefPmqXfv3pnrBgwYoHnz5jmsCgAAAAAKH8G0mFiwYIFat26t6tWrZ67r0qWL1q9frx07djisDAAAAAAKF8G0GPjqq6/0+9//Xn/5y18u2Pbss89q6NChSkpKclAZAAAAABQ+gmkxUL58eb311luqU6fOBdt69uypBx54QCdOnHBQGQAAAAAUPmOtdV2DJMnn89m4uDjXZQAAAAAACoExZr211pfdNnpMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMAQAAAABOEUwBAAAAAE4RTAEAAAAAThFMS4mZM2eqQYMGaty4cZZP7dq1tWjRItflAQAAAECOjLXWdQ2SJJ/PZ+Pi4lyXAQAAAAAoBMaY9dZaX3bb6DEtxgKBgLL7w4G1VoFAwEFFAAAAAFDwPK4LQM6effZZLVq0SEFBWf9+kJ6erjvuuEPjxo1zVBkAAAAAFByG8gIAAAAACh1DeUuwlJSUC9b5/f4s3y/1xwVrrdLS0gq0LgAAAAAoKAzlLeauv/56eb3eLOuqV6+upUuXZn6fMWOGZsyYcUG7c/x+v5577jkNHTq0UGsFAAAAgLxgKC8AAAAAoNBdbChvnnpMjTEPSDrX/VZV0n+ttWPOa+OR9H3GR5IettbG5+V8AAAAAIDSK0/B1Fo7S9IsSTLGvCjpzWyatZb0jrX2ibyXV3a9++67euaZZxQSEpLt9pSUFE2ZMkW33XZbEVcGAAAAAAUrX8+YGmPqS6ptrc1uDG5HSQOMMT0kxUsaY61lBp7LNGzYMA0bNsx1GQAAAABQ6PI7K+9Dyug5zcY6SZHW2usleSX1O7+BMeY+Y0ycMSbuyJEj+SwFAAAAAFAS5TmYGmOCJPWQFJtDk6+ttQczluMkNTm/gbX2FWutz1rrq1mzZl5LAQAAAACUYPnpMe2qs5Me5TSt71xjTBtjTLCkQZI25eNcAAAAAIBSKj/BtLeklZJkjGlhjJl63vanJM2VtFHSamttTD7OBQAAAAAopfI8+ZG19g8/W94qadJ52zfr7My8AAAAAADkKL+THwEAAAAAkC8EUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBNNiburUqfrHP/7hugwAAAAAKDQE02IuLCxMHo/HdRkAAAAAUGgIpgAAAAAAp+iKK2ZeeuklzZs3T16vV5K0b98+BQcH691335Uk+f1+3XXXXbr//vtdlgkAAAAABcZYa13XIEny+Xw2Li7OdRnFzvPPP6+KFSsSRAEAAACUaMaY9dZaX3bbGMoLAAAAAHCKYAoAAAAAcIpgWsylp6eruAy3BgAAAIDCQDAt5vx+v9LS0lyXAQAAAACFhll5i7lJkya5LgEAAAAAChU9pgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKdyHUyNMR5jzF5jTGzG55c5tJttjFltjJmU/zIBAAAAAKVVXnpMW0t6x1obkfGJP7+BMWawpGBr7Q2SrjLGNMlvoQAAAACA0ikvwbSjpAHGmLUZvaKebNpESHovYzlKUpfsDmSMuc8YE2eMiTty5EgeSgEAAAAAlHR5CabrJEVaa6+X5JXUL5s2FSQdyFg+Lql2dgey1r5irfVZa301a9bMQykAAAAAgJIuu97OS/naWpuSsRwnKbthuqcklctYrigmWQIAAAAA5CAvgXGuMaaNMSZY0iBJm7Jps14/Dd9tI2l3nqoDAAAAAJR6eekxfUrSPElG0keSEowxU621P599d5GkL4wx9ST11dnnUgEAAAAAuECug6m1drPOzsz7c5POa3PCGBMhqZekv1prk/JaIAAAAACgdMtLj+llsdYm6qeZeQEAAAAAyBaTEgEAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpgCAAAAAJwimAIAAAAAnCKYAgAAAACcIpg6EggEFAgELro9PT29CCsCAAAAADcIpo4888wzqlSpkqpWrZrtp1KlSpo9e7brMgEAAACg0BlrresaJEk+n8/GxcW5LgMAAAAAUAiMMeuttb7sttFjCgAAAABwimAKAAAAAHCKYAoAAAAAcIpgCgAAAABwimAKAAAAAHCKYAoAAAAAcIpgCgAAAABwimAKAAAAAHCKYAoAAAAAcMqTl52MMVUkvSspWNKPkoZaa/3ntfFI+j7jI0kPW2vj81ErAAAAAKAUymuP6QhJL1hrb5J0SFKfbNq0lvSOtTYi40MoBQAAAABcIE89ptbal3/2taak/2XTrKOkAcaYHpLiJY2x1qbl5XwAAAAAgNIrX8+YGmNukFTNWrsmm83rJEVaa6+X5JXUL5v97zPGxBlj4o4cOZKfUgAAAAAAJVSeg6kxJlzSi5J+lUOTr621BzOW4yQ1Ob+BtfYVa63PWuurWbNmXksBAAAAAJRgeQqmxpgQSfMlTbDW7smh2VxjTBtjTLCkQZI25a1EAAAAAEBplqdnTCX9WlI7SRONMRMlrZDktdZO+lmbpyTNk2QkfWStjclXpQAAAACAUimvkx/NkjTrEm026+zMvAAAAAAA5Chfkx8BAAAAAJBfBFMAAAAAgFMEUwAAAACAUwRTAAAAAIBTBNNCFggEFAgELro9PT29CCsCAAAAgOKFYFrInnnmGVWqVElVq1bN9lOpUiXNnj3bdZkAAAAA4Iyx1rquQZLk8/lsXFyc6zIAAAAAAIXAGLPeWuvLbhs9pgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnCKYAAAAAAKcIpgAAAAAApwimAAAAAACnPK4LKMleffVVzZgxQ3Xr1r1g2+nTp/Xll186qAoAAAAAShaCaT6EhobqiSee0IgRIxQTE6ONGzdq/PjxMsaoe/furssDAAAAgBKBYJoPQUFnR0IPHTpU27dv1+nTp7Vo0SJFR0fLGOO4OgAAAAAoGQim+ZCenq7jx4/r5ptv1jXXXKNdu3apd+/e2rx5s+vSAAAAAKDEIJjmw+HDh1WlShVVrFhRHTp0UIcOHRQIBBQaGuq6NAAAAAAoMQim+bBnzx6NGjVKTzzxhDweT+a6nTt3Oq4MAAAAAEoOgmk+fPPNN2revLk8Ho9iYmIkSREREW6LAgAAAIAShmCaR0eOHFFiYqKqVKmi1q1bKzIyUpJUu3ZtSWLyIwAAAAC4TATTPIqLi9PIkSMlSS+88ELm+sWLF6tt27a6+eabXZUGAAAAACWKsda6rkGS5PP5bFxcnOsycsVae0HPaHbrsnPixAl5vV6VK1eusMoDAAAAgGLDGLPeWuvLbhs9pvmQXQC93CG8Tz75pPx+v2677bYs61NSUtS7d+8CqQ8AAAAASgKCqQOrV6/W1q1bNWzYMO3evTvLNr/f76YoAAAAAHCEYFrEdu7cqT/84Q8aPny45s6dm6WHNS0tTfPnz3dYHQAAAAAUvSDXBZQ1DRs21HvvvafDhw9r5syZ6tevn/r376+YmBg1bNhQFStWdF0iAAAAABQpekyL2MGDB3X33Xfr+++/17JlyxQaGqoDBw5o6dKl2rRpk/r166dx48apf//+rksFAAAAgCJBj2kRa9iwoZYvX66IiAhFR0erfv36mjVrlj777DN17txZK1asIJQCAAAAKFMIpo6kpqbK6/XqmWee0ZIlS7KsBwAAAICyhKG8jlSrVk2RkZGZ3yMjI7VhwwYNGzZMCxcudFgZAAAAABQtY611XYMkyefz2bi4ONdlOJGWlqY77rhDDRo00MyZM12XAwAAAAAFzhiz3lrry24bPabFgMfj0RtvvKHKlSu7LgUAAAAAihzPmBYThFIAAAAAZRXBFAAAAADgFMEUAAAAAOAUwRQAAAAA4BTBFAAAAADgFMEUAAAAAOAUwbQQREREyO/3uy4DAAAAAEoEgmkhSExMVEhIiOsyAAAAAKBEIJgWAmNM5rK1VmlpaQ6rAQAAAIDizeO6gNKqY8eOkqT09HT5fD69/PLLjisCAAAAgOKJYFpI1qxZ47oEAAAAACgR8jyU1xgz2xiz2hgzKT9tAAAAAABlW56CqTFmsKRga+0Nkq4yxjTJSxsAAAAAAPLaYxoh6b2M5ShJXfLSxhhznzEmzhgTd+TIkTyW4l5aWpoCgUCO2wOBABMgAQAAAEAO8vqMaQVJBzKWj0tql5c21tpXJL0iST6fz+axFufeeOMNvfLKKwoKOpvzw8LCMic/ks5OgPTwww9r1KhRrkoEAAAAgGIrr8H0lKRyGcsVlX3P6+W0KRXuuece3XPPPa7LAAAAAIASKa9hcb1+GprbRtLuPLYBAAAAAJRxee0xXSTpC2NMPUl9JQ0zxky11k66SJuOFxwFAAAAAFDm5anH1Fp7QmcnN1ojqYe1dtN5oTS7Nkn5K7XkiIiIkN/vd10GAAAAAJQIee0xlbU2UT/NupvnNqVRYmKiQkJCXJcBAAAAACVCqZ2QqCg9++yz2rx5c+b3o0ePKi4uTpJkrb3gVTGpqakXfb0MAAAAAJQlBNN8ePjhh7V//34NGDBAI0aMUGJioqSzPaZdu3ZVpUqVVLlyZVWsWFHXX3+9unTpoi5duqhz586KjY295PFnzpyp1157rZCvAgAAAADcyvNQXkh79+5VWlqaWrZsqfHjx2v69OmaOnWqJGnPnj2qVauWJGnAgAH65z//qV/84heXPOaYMWO0fft2GWOUkJCgoKAgvf3227LWqnXr1nrxxRcL9ZoAAAAAoKgRTPPBGJO5PGLECKWnp0uSAoFAZij9ucTERFWrVk1vvPGGXn/99cznUM8N6w0ODlZ6eroOHjyoyZMn69SpUwoLC1OPHj308ccf67777iuCqwIAAACAokUwLQB+v18//PCDatWqpfj4eHm93gvaHDlyRL1799brr7+u0aNHa/To0Znb/vjHPyoiIkI9e/aUJK1atUrR0dGqW7euJGnatGkaM2YMEyoBAAAAKJUIpvmUmpqqoUOH6sYbb9TDDz+sOXPmqGrVqlnaWGtVrVo1vf/++xo4cKBmz56thQsX6quvvpIkbdu2TcuWLdNjjz2mXbt2qXr16mrQoIG+/fZbGWPUpEkTjRs3TqmpqZowYYL69Onj4EoBAAAAoHAYa63rGiRJPp/PnpvJtqQYNGiQDh06pMaNG2vHjh06ceKE9uzZo+DgYDVv3lwez9ncv337dv3pT3/S7373O23dulVffvml5s+fr48++kj/+Mc/1Lx5c0nSt99+q9tuu00TJ05UUFCQTp8+rWPHjqlNmzZ6/vnnXV4qAAAAAOSLMWa9tdaX3TZm5c2H77//Xvfff7/++c9/6uabb1a9evV06NAhzZ07Vx6PR8uWLdOaNWvUpUsXDRkyRJLUokUL3XvvvQoKyvpPn5iYqE2bNmny5MlavXq1ateurdjYWFWtWlUnTpzQyJEjdfToUReXCQAAAACFimCaD8uXL9ewYcPUrVs3eTweLVmyRFWqVNGtt96qu+++W7t27ZIkpaSkKCUl5aLHiouLU3x8vObPn69Tp06pTp06SkpK0ooVK9SvXz81b95cTZo00eeff14UlwYAAAAARYZnTPOhRo0aks6GyvN7QMeMGZO5HB0dfclj9erVS2lpadq7d68kafHixZKk5s2ba9CgQRo0aJDuvPNOXXnllZKkjz/+WMeOHcsyiRIAAAAAlERlJpgePHhQQ4cOvWBmW7/fr6VLl6pcuXJ5Pvb5ofRynHu297rrrlPt2rUVEhKi3bt3q1atWgoJCVFERIS2b9+ujz/+OHOfq666KnN54cKF2r59O8EUAAAAQIlXZoJp3bp1tXLlykI/z4gRI/S73/1O119//UXbpaamSpJ69OihhQsXaubMmUpKStLWrVvVsGFDxcTE6Mcff9Stt96qQCCgp59+Wt26dcvc/7nnntPEiRML9VoAAAAAoCiUmVl5rbUyxuR6W26NHj1a27ZtU6VKlSSd7ZG9VCBOS0tTamqqnnrqKYWFhalp06Zq0KCBVq9erR9++EETJkxQuXLlFBwcnLnP2rVr1aRJE1WrVq1A6gYAAACAwnSxWXnLTI+pz+eT1+vVrl27VKdOHZ06dUpBQUGqXr266tevr4ULFxbYuV566SX5fNn+e2frk08+0YQJE9S+fXvt3btXb7/9tipWrKgqVaqoXbt2uuaaa7RgwQJ16NAhc59L9cgCAAAAQElRZnpMzxk4cKBeeOEFRUdHKywsrECe0dy3b59at26tNm3aZFm/fft2LV269IL150tISJDH41H16tVlrdWMGTPUqlUrdevWTaGhodq3b5/q1KmjsLCwfNcKAAAAAC7QY/ozBw4cUK1atQr0mKGhobruuusUExOTZf3o0aMvmGwpO/Xq1dOjjz6qbdu2yePxaN++fapQoYLCw8OVkpKifv366dFHHy3QmgEAAACguChTwTQ+Pl5Vq1bNfP7znNTUVHm93jwf1+/3a/369YqIiMiyfvv27ZcdKP/2t7/l+fwAAAAAUJKVmWCakJCgESNG6LXXXpN09hUvR48elSRNnjxZLVq00KhRo/J07LVr12rDhg1KTk5WixYttG3bNtWtW1cej0fbtm0rsGsAAAAAgNIo9y/gLIEOHjyo7t2766mnnsqcNCgiIkJLlixRx44dtW3bNvXv3z9Pxz5z5oz++Mc/Kjw8XE8++aTWrVunjRs36umnn1YgENA999yjxMTEgrwcAAAAAChVykSPad26dbV169Ysw3WbNm2qZcuW5eu41lp9+OGHatKkibp06aLRo0frqaee0kMPPZQ5q+7jjz+uzZs3q2vXrvm9DAAAAAAolcpEMJWUr2dIczJ27Fh5PB4lJCRo7ty5atOmjfbu3auwsDBNmTJFkjRy5Eg1b95cderUybLv9u3bFRUVpdatWxd4XQAAAABQkpSZYFoYzk1YdPvtt6tixYoaMWKEAoFA5vb//Oc/8ng88ng8io2NzbLv6NGjVaFChaIsFwAAAACKJYJpHj355JNasWKFjDHavHmzRowYoW+//VY//PCDPvnkEwUHB+vkyZOaPXu29uzZo1atWqlGjRqZ+2/fvl1PPvmkuwsAAAAAgGKiTEx+VBiefPJJff7554qNjVXNmjUVGxur/v37q06dOho7dqzmzJmj0NBQPffccwoEAqpXr54CgYBmzpyp2NhY9enTx/UlAAAAAECxQDDNp2XLlmnnzp3q06eP9uzZI2ut/t//+3+644471LNnT61YsULly5fXK6+8oi+++EJt2rRxXTIAAAAAFCsE03xIS0vT5MmT1bJlS8XGxio2Nla33367HnnkEdWrV0///e9/dddddykxMVHXXnutwsPDFRkZqcjISEVFRWV7zIkTJ2rXrl2SJL/fryFDhhTlJQEAAABAkSsVz5gePHhQQ4cOVUhISJb1fr9fS5cuVbly5Qr8nKdPn9avf/1rXXXVVVq8eLEiIiIkSdu2bVNYWJiSk5N1ww03aObMmerSpYu+/PJLNWrUKHP/0aNHZ3vc9evX689//rMkKTo6WuXLl9f27dslSVddddUF1wgAAAAAJV2pCKZ169bVypUri/Sc69atU506ddSpUyf9+c9/VnJyslq0aKHmzZvr9ttv16BBg9SvXz/17t1bycnJuueee+T1erVkyRJJZ3tbjTGZxwsEAqpRo4batGmjdu3a6eabb9aGDRtUuXJlTZs2TWvXrtX777+vHTt2KDIyUuXLl89ST2pqaqG8EgcAAAAAClupCKbW2iwh73K35UfXrl113XXXqV69evr66681cOBAtWrVSqdPn9Z7772nvn376syZM6pTp4569eqlv/71r2rUqJFSUlLUuXNnScrybtPg4GC1a9dOy5YtU2xsrF5++WXVrVtX06dPV+XKlfXQQw/J4/Fo6tSpatq0qaKionTkyBHt2rVL+/bt07Bhw/TAAw8U+HUCAAAAQGErFcHU5/PJ6/Vq165dqlOnjk6dOqWgoCBVr15d9evX18KFCwv8nAcPHlTv3r3l9/s1d+5cXXHFFdq1a5fq1q2ruLg4jRs3Tunp6QoEAlq1apVuv/12BQUF6a677tLatWsVFHTh472bNm1SRESEfvjhBw0aNEijRo3SyJEj9dFHHyklJUX/+c9/1K1bN23cuFGJiYm6++679Zvf/Eaff/55gV8fAAAAABSVUhFM169fL0kaOHCgXnjhBUVHRyssLCzH5zgLQu3atdWuXTtVqlRJp06dUvv27XX48GFVqlRJP/zwg6644go1btxYb7311mUfs23btoqJicmcSOnqq69WcHCwvv76a50+fVqvvvqqevbsKY/Ho4YNG+qqq67KNuACAAAAQElSqlLNgQMHVKtWrSI516ZNm3T77berQYMG6tatm7Zt26bQ0FCNGTNGnTp10uTJk/X666/n+zwvvfSSWrZsqe+++y7LM6TTp09Xnz59tHbtWvXp00fdunXT/v37830+AAAAAChqpSaYxsfHq2rVqqpUqVKW9ampqXk6Xlpa2kW3b968WS+++KKSkpJ011136dChQ9q/f7/69eunPXv26JFHHlF0dHSuzrlhwwZFRETokUceyVxXr149BQcHKxAI6LHHHstc/9hjj+mzzz5Tt27d9P7772vlypX6xS9+kavzAQAAAEBxUCqCaUJCgkaMGKFnnnlGkhQUFKSjR49KkiZPnqy5c+de1nG+++473Xvvvfrxxx/Vv39/DRgwQAMGDMgcsvvNN99ktq1fv746deqkGjVq6JFHHtENN9ygkJAQPf3006pUqZIGDhyoq6+++rKvIRAI6LrrrlNsbKxmzZqVOevum2++qSZNmqh58+aqUqVKln2stbrmmmu0efPmyz4PAAAAABQ3JT6YHjx4UN27d9dTTz2l66+/XpIUERGhJUuWqGPHjtq2bZv69+9/yeMkJCTo888/16FDh7R9+3YtXbpUnTt3Vvfu3VWzZk299dZbeuKJJzLbT5s2TR06dNCwYcN0+vRpJSYm6ocfftC2bds0cuRItWzZUikpKZd9HcHBwYqKipIk3XDDDRo/frwk6ZZbbtF//vOfC8L1/v37de+996pHjx56//33lZycrB9//PGyzwcAAAAAxUWJn/yobt262rp1a5bnL5s2baply5bl6jgpKSnasGGDTp8+rZMnT2rQoEE6evSovvzyS1WpUkXr1q1TvXr1FBkZKUn66quvdN999yklJUXt27dXYmKijh8/rk2bNmnTpk2qWLGi3n333QvOk5aWpsOHD6t+/fqXVVe1atUyl9PT02Wt1ZEjR/T2229r8ODB6tSpk5588km9+uqrOnnypCZNmpSr6wYAAAAA10p8j6mkLKE0r6688kqFh4erWrVqaty4sU6ePKmgoCDVrFlT1lqFhITI7/drz549uuOOOzRlyhTFxMToyiuv1AcffKAaNWroqaee0uLFi7V48eILQqm1VmlpaUpOTtYTTzyhtLS0LM+xTpo0SStWrLhojSkpKUpJSVGPHj20bNky/fKXv9SiRYv0+uuva+XKlRo1alS+/x0AAAAA5N7HH3+sN954w3UZJZax1rquQZLk8/lsXFycs/Ofe8azYsWKat++vRYvXqz69etry5YtOnPmjKpUqaJOnTqpQ4cO8ng8Wr9+vaZPn66+ffvqcur+97//rTfeeEMtW7bUli1b1LJlS61Zs0Z33nmnjh49quTkZPXp00cRERGFf7EAAAAACtTo0aO1fft2rVmzxnUpxZYxZr211pfdtlLRY1oQ5syZo/bt26tt27a6//771axZM8XGxqp79+56+OGH1ahRI5UrV05HjhxRQkKC6tWrp+nTp6tfv36XdfyuXbuqa9euCg0N1TfffKPQ0FANHz5czZs3V3p6eiFfHQAAAIDC9Nxzz6l169auyyixSvwzpgWlV69euvbaazVnzhw1a9ZMMTExqly5sk6dOqVy5copOTlZ69atU2hoqEJDQ9WyZUslJiZq/vz5l3X8evXq6dprr1VCQoIqV66sq666Ss2bN1doaGghXxkAAACAwrZr1y49++yzrssosQimGRo2bKifD2vu2bOnPvnkE9WrV09ffPGFWrdura5du6pPnz6ZbebNm3fZvZ1HjhxRcnKygoLOdlKfe6VN7dq1C/ZCAAAAABS5c28IQd4QTH8mEAjIGCNJSk1NlSQZY/T999/L7/erWbNm8vl+GhJ97vUulyMhIUHHjx+XMUbWWgUCASUkJKh69eoFexEAAAAAUMIQTH/m6quv1osvvijpbOiMj4/XNddco+7du8vr9SomJkZbtmyRtVbGGG3duvWye0zbtGmjp59+WjVr1lTjxo21evVqVatWTW3btpXf7y/MywIAAABQDMybN0833XSTatSo4bqUYodgmoOEhASNGDFCr732mkJCQvTXv/5VZ86c0bhx4zRhwgS1aNEi169nOXz4sObNmyePx6Pdu3frySef1A033KCOHTvq17/+tYKCgvTXv/5VjRo10h133FFIVwYAAADAhVWrVunQoUMaO3as61KKHYJpNg4ePKju3bvrueeeyxwrftNNN+mBBx7QggULVKdOHT3++OO5Pm4gEFDPnj1ljNGZM2fUpEkTSdLrr7+uBQsWqHv37jp69Kjatm1bkJcDAAAAwIH4+Hj99re/VYUKFSRJP/74o3bv3q3ly5dLkpKSkvS3v/0t83HBc6Mxz81LU5bwHtMcpKamyuv15usYx48fV3h4uKSzs3SFh4erSpUqF7Tz+/06fvy4li9frmXLlunRRx9Vq1at8nVuAAAAAMXDwoULtXr1aj3//POSpPvvv1+dO3fWqFGjMh8TlKTPP/9cf/rTn5SQkKBf/OIXstYqMjJSEyZMkHT2FZSLFi0qsfPUXOw9pvSY5iCvofTHH3/Unj175Pf7NWbMGEVFRenkyZNq166d9uzZk+1fQR588EHt3LlTxhjFxcXpu+++y9y2ceNG7dixQ7Vq1crfBQEAAAAoUtZaPffcc1q4cKFmzZqVuX7w4MGaPn261qxZo5deeilzfffu3bV8+XK1b99eY8eOVd++fWWM0XPPPafhw4crODg4s/e1tCGYFrDDhw9rxIgR2rFjh2rXrq0GDRooNTVVwcHBatiwoSpVqqRZs2apf//+mfu89tprks525ffp00fR0dGZwbhdu3aqWbOmk2sBAAAAkHdpaWnyer369NNP1aVLF/33v/+Vx+PR2LFjFRUVpdOnT1+wz+LFi1WhQgV169ZN3bp104cffqgtW7ZkvjWktCKYFrCrrrpKzz77rBYvXqzBgwfriy++0Pz58zVu3Dh99dVXeuKJJ1S3bt1s93311Vc1fPhw/d///Z+aNWumCRMmZOnaBwAAAFByeL1ePfroo5KkcePGafz48Tp58qSmTp2qevXqXdB+/fr1GjZsmEaOHKkJEyboxIkTevDBBxUWFlbqM0HZe6q2CCxcuFBRUVGaO3euPvvsMyUmJmrWrFlatmyZxowZo0AgcME+8fHxmj9/vh544AG9+eabSklJ0bZt27J9JhUAAABAyXLjjTfqgw8+0K5du9SnT59s2zRr1kwfffSRrrvuOqWkpGjdunX6wx/+UMSVupGrYGqMqWKMWWKMiTLGfGCMCcmhnccYs9cYE5vx+WXBlFv8ffrpp3rttdfUsGFDLV26VIFAQFdccYVq1KihRo0a6bvvvtN///vfLPusWLFCd955p9599115vV55vV4988wzOn36tK644ooCqy0QCOjWW29VWlqapLPDjocOHVpgxwcAAADwkyNHjujtt9/WPffco3vvvVdLly7Vvffeq44dO+r+++/XnDlzdPz48cz2p0+f1gcffKDPPvtM69at07hx43TkyBGHV1B0cjuUd4SkF6y10caYWZL6SPoom3atJb1jrX0ivwWWNLVq1VL//v310ksv6cYbb5TX61XHjh31v//9T3FxcVq+fLlq166d2T4hIUF/+tOf9PHHH6tRo0aSzk4T3aFDB505c0YvvvhigdX2/vvvq3fv3jp69Khq1KihDz74QI0aNdKaNWsknX2eNSQk2781AAAAAMilxMREbdq0Sffee686dOggSWrbtq1GjhypqKgorVq1SpUqVcpsX61aNU2YMEFr167V0qVLNXnyZIWEhOj111/PdtRlaZLn18UYYxZIet5auyabbQ9KekjSj5LiJY2x1qZd7HjF7XUx+dG0aVP973//U3Jysrxerzwej86cOSOPx6PWrVtr9erVRV7ToUOH9NBDD2n+/Pm67bbb9Mc//lHjx49X9+7dJUkLFizQp59+mu1YdwAAAACFb9++fdq8ebOWL1+u2NhYNW/eXNWrV9eMGTMknX1dTExMjEJDQ90Wmkd5fl2MMeZfkpr9bNVya+1TxpgbJFXLLpRmWCcp0lp70BjzlqR+yqZn1Rhzn6T7JBXokFXXunXrprp162rhwoU6ceKEGjVqpD179qhTp07av3+/7rnnnsyZeItKfHy8Nm3apMaNG2v48OHavn27IiIiNHHiREnSpk2bVK5cuSKtCQAAAMBPduzYoY8++kht27bVLbfcombNmmW+NnL48OH64YcfSmwovZRc95gaY8IlRUkaYq3dk0ObUGttSsbybyV5rbXTL3bc0tJjeubMGU2cOFGvvPKKypcvr9OnT+vBBx/UkiVLtH37dklSy5YtNW7cON15551FWltqaqpGjhypN998Uxs3btTx48eVnp6uAQMGqH///vrggw8YygsAAAAUQ4cOHVLt2rVL9Oy8F+sxze3kRyGS5kuakFMozTDXGNPGGBMsaZCkTbk5T0kWFhamevXqqXv37rLWqkmTJpo/f76OHTum5s2bKzg4WJ07d9bw4cOLvLZzQXjq1Kk6duyYIiIi9PTTT+uHH35QWloaoRQAAAAopurUqVOiQ+ml5KrH1BjzgKRn9FPQnKWzz5Deaa2d9LN2rSTNk2QkfWStnXipY5eWHtNz9u/fr1/96lf6wx/+oL/97W/yer36zW9+o7Fjxyo2NlaVK1cu8preffddhYeH65prrlGdOnXk9Xp14sQJVa5cWX379tWSJUuKvCYAAAAAZUOenzE9n7V2ls6G0fNNOq/dZp2dmbfMmTBhgoYMGaKaNWvq+PHjOnDggLZt26bOnTtLkqy1yuuEU/mxe/duffvtt/r222/l9/s1ePBg3XbbbZkBOSUlpchrAgAAAAApl0N5cXFnzpzRqlWrVLFiRQ0cOFDbt2/XW2+9pV27dmn//v2aMWOG9u/fryFDhmjLli1FWlvlypXVunVrzZw5U/PmzdNtt90mSTp27JhuuOEGtW/fvkjrAQAAAIBzcvseU1zEv/71L3Xv3l3NmzdXw4YNVb9+fVWvXl0tWrTInAH3+uuv12effSaPp2j/6cPDw3XLLbdcsL569epOXl8DAAAAAOfQY1pA9u3bp+eff14ej0crVqxQfHy8rLU6fvy4EhIS9OSTT6pPnz6qWbOm7rjjjose6+uvv1aNGjXk8/myfMLDw/XNN98U0RUBAAAAQNGgxzQHx48fV3h4uCRp7969l3zP6hdffKHHH39c3333nSZMmKBrr71Wy5cvV/369eX3+9WsWTN5PB598MEH8nq9F+z/5Zdfqk6dOrr66qu1aNEi9erVS++8806WNsOGDWPmXAAAAAClDsE0G6dPn9att96qTz/9VMHBwRo1apQ+/vjji86ke+edd2rVqlU6fvy4Pv30U82ePVsrV67UrbfeqrCwMF1//fVKSkpS586d1a5dOz366KNq1qxZ5v7PPvusxo4dq7CwML3zzjs6fvy4IiIispxj69atpXqKaAAAAABlE0N5z/PYY4+pV69eSklJUY8ePdS+fXslJSXp5ptv1tixYy/rGOHh4QoODtawYcP05z//WampqSpfvrxuu+02ffnllxo8eLAaNGiQ2f7w4cNKSEhQRESE5s6dq5MnTyo4OFgej0fBwcH67W9/q9jYWN14441KT08vrEsHAAAAACfoMT3P008/rVWrVsnj8WjVqlVKSkpS//79FQgELjlzbXp6utLT0+X3+7Vs2TI9//zzkqQjR46oSpUqkiSv16ubbropy37/+Mc/VLVqVZ08eVKLFi3S4MGDtWLFCp05c0YHDhzQE088oRdeeEGSFBwcXAhXDQAAAADuEEzPY63NtlcyEAhc8v2jKSkp8vv9euyxx3TnnXfqmmuu0ejRo5WYmKimTZtmu8+hQ4f07rvvqmHDhvr73/+uu+66S0ePHtWLL76oiIgIPf/886pRo4ZGjx6dWUcgECCgAgAAACg1zKXCVlHx+Xw2Li7OaQ07d+7UAw88oIoVK0o6+17S9PR0lS9fXpJ06tQpzZw5Uy1btrzocay1l/0s6F/+8hddeeWVeu211/Txxx/rvffe0+9//3slJSUpODhYqampqlu3rqpXry7pbK/slClTNHDgwHxcKQAAAAAULWPMemutL9ttBNOsUlNT5fF4ZIzRjBkz1KBBAw0ZMkSSlJaWVuDvH7XW6tixYxo2bJhiYmIkSVOnTlWXLl0UERGhF154QdWqVdPdd99doOcFAAAAgKJ0sWBapobyxsbGas2aNfr973+v/fv3q379+oqMjFR0dLQOHjyo+vXr61e/+pWOHTumoKAgrV27VmlpaZozZ46stQoNDdX7779foDXl1LP6yCOPqGrVqvr+++8JpQAAAABKtTIVTCVl9njecccd+uyzz1SuXDnFx8fr73//u2bPnq25c+dKkhYtWqSGDRuqWbNmOnbsmCZNmpTt+0cLgrX2gudXZ8yYccHrYgAAAACgNCozwfTtt9/Ws88+q1OnTqlevXqKj4/X4cOHJUlvvPGGjh8/rjNnzujll19WVFSU2rdvr7///e8KDg7WggULcnz/aEFITU2V3+/P/J6Wlqa0tLQCPQcAAAAAFFdl6hnT2NhYxcXFqVq1atqzZ4/WrVunY8eOSZLatm2rUaNGKSkpSZ06dVJ4eHiWfVNTU7VixQp16dIlczIkAAAAAMDl4RlTSQkJCVq6dKmWL1+uRx55RL///e91+PBh3XfffZo+fbqqVq2qpKQkde3aNdv9s3v/KAAAAAAg/8pMMN20aZOqVq2q22+/XcOHD1dERIQ8Ho82bdqksWPHqkKFCvrwww9dlwkAAAAAZU6ZCaZ9+/ZVuXLldG64cGxsrCRpwIABWrx4scPKAAAAAKBsC3JdQFEzxuj06dNKT0/Psj4QCCg5OblQz52UlKQbb7yxUM8BAAAAACVNmZn86Ouvv9Zjjz2me++9V4cOHdKHH36Y5R2i1loNHDhQv/3tbwvl/MOGDdN3330nr9erkJAQSdL333+vvXv3Fsr5AAAAAKA4YfIjSY0bN9b06dPVunVrSSq0AHq+QCCg9PR0eTwezZkzR999952++uor/elPf9KAAQOUnp4ua62Cg4OLpB4AAAAAKG7KTDAtX758ZigtSp9//rmmTJmiLVu2aM+ePZkBNCIiQvHx8YqIiNCjjz6qW2+9tchrAwAAAIDioMw9Y1rUbrzxRn366adq2rSpVq5cqVq1amnMmDGKjo5W27ZttXLlSkIpAAAAgDKtzPSYuvTmm2/q8ccflzFG77zzjnbs2KHp06erT58+rksDAAAAAOcIpkUgKSlJr7zyiiZPniyv1ytjjPx+vzwej/x+vyZOnOi6RAAAAABwhmBaBEJDQzV58mSdOnVKNWrUkMfj0aFDh1S1alVt377ddXkAAAAA4BTBtJBNnDhRCxcuVIUKFRQIBC7oMU1KSlJiYqKeffZZ16UCAAAAgBNl5j2mAAAAAAB3LvYeU2blBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAAORJQkJCgRzHUyBHAQAAAACUOX379lVsbKyOHj2qt956S8HBwZKkXr16qXPnzpd9HHpMAQAAAAC5smTJEvXs2VMHDx7U0KFD9cknn2jIkCG65ZZbNHfuXDVs2DBXx6PHFAAAAACQK3379lVycrJ27NihoUOH6qqrrpK1Vnfffbfq1q2rKlWq5Op49JgCAAAAAHJt3rx5atOmjf71r3/pxIkTGj58uBo1aqTHHntMN954ozZs2HDZx6LHFAAAAACQKzt37tTXX3+tl156SXv27FGlSpV08803a8SIEbLWqkWLFqpQocJlH89Yawux3Mvn8/lsXFyc6zIAAAAAAJdp48aNWrBggaZOnaqbbrpJhw4dUlpammrXrq2YmJjMyZAkyRiz3lrry+449JgCAAAAAHJl7969mj9/vlatWqUdO3aoWbNmioqK0oIFC3Tq1CmNHj06V8cjmAIAAAAAcsXr9erqq69Wu3btFBMTo2HDhsnv9+vciNz09HQFAgF5vd7LOl6uhvIaYzySvs/4SNLD1tr4HNrOltRC0ifW2qmXOjZDeQEAAACgZImLi9O///1vtWjRQm+++aY8nrN9n2lpaerXr5/Gjx+f2bYgh/K2lvSOtfaJizUyxgyWFGytvcEY87oxpom1dmcuzwUAAAAAKMZ8Pp98vrNZ8+67787zcXL7upiOkgYYY9YaY2Zn9KBmJ0LSexnLUZK6ZNfIGHOfMSbOGBN35MiRXJYCAAAAACgNLhpMjTH/MsbEnvtIqikp0lp7vSSvpH457FpB0oGM5eOSamfXyFr7irXWZ6311axZM08XAAAAAAAo2S4aTK21Y6y1Eec+kqZZaw9mbI6T1CSHXU9JKpexXPFS5wEAAAAASB988IE2b96c+T0hIUFDhgxxWFHRyG1gnGuMaWOMCZY0SNKmHNqt10/Dd9tI2p2n6gAAAACgDGnatKnGjBmjHTt2SJJCQkIue2bbkiy3kx89JWmeJCPpI2ttjDGmhaQ7rbWTftZukaQvjDH1JPXV2WdTAQAAAAAX0axZM61atUrTpk3Thx9+qNDQUH3zzTeKjIzU3r17tXTpUl155ZWuyyxwueoxtdZutta2ttb+0lo7MWPd1vNCqay1J3R2AqQ1knpYa5MKqmAAAAAAKI2++eYbtW/fXlFRUQoEApo2bZoWLlyoiIgIxcTEqFOnTjLGuC6zUBTas5/W2kRr7XvW2kOFdQ4AAAAAKC2aNWum+fPn63//+5/rUoockxIBAAAAQDHRuHFjNWjQQJL02GOPaciQIYqNjVVkZKSioqIcV1d4CKYAAAAAUEzs2bNHf//73yVJ06dPzzKU96abbnJcXeEhmAIAAABAMTFx4kSNHTtWUtnqMc3trLwAAAAAgEJw4MABnThxQl26dNHSpUs1ffp0RUREZG4fPXq00tLS3BVYiIy11nUNkiSfz2fj4uJclwEAAAAAzlhrS+3Mu8aY9dZaX3bbGMoLAAAAAMVEaQ2ll0IwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAAAAOEUwBQAAAAA4RTAFAAAAADhFMAUAAACAUmjhwoVKSUlxXcZl8bguAAAAAABQsI4fP66//e1vGjx4sIYNG6ZDhw5l2b5o0SJVrVrVTXHZoMcUAAAAAEqZGTNmaMqUKfr66681d+5c/eY3v9GgQYP02WefqWLFigoJCXFdYhYEUwAAAAAoRTZu3KglS5bIGKNf//rXCgoK0qlTp1SrVi2FhYXpzJkzKl++vOsysyCYAgAAAEApkpycrJtuukkTJ07UX/7yFwUHB+vkyZMKDw93XVqOeMYUAAAAAEqRTp06qXr16vr+++/Vq1cvPfTQQ1q6dKnCw8P1/PPP68CBA65LvAA9pgAAAABQiuzbt0+33HKLvF6v/u///k8vvfSSevXqpTfeeEMxMTH6xS9+4brEC9BjCgAAAAClSPny5fX444+rS5cuatKkiaSzs/RWr15dkpSenu6yvGzRYwoAAAAApUhYWJiaNm2qf//73+rdu7cCgYASExMVHh6ulJQUhYSEFLtwmqseU2PMA5KGZnytKum/1tox2bTzSPo+4yNJD1tr4/NRJwAAAADgMuzbt0/vvvuuRo0apb59+2rgwIEqX768br/9dklSaGio/vnPf+rBBx90XOlPjLU2bzsa86KkN621cdlsaydpqLX2ics9ns/ns3FxFxwKAAAAAFAKGGPWW2t92W3L01BeY0x9SbWzC6UZOkoaYIxZa4yZndGDCgAAAADABS4aTI0x/zLGxP7sMzlj00OSZl1k13WSIq2110vySuqXw/HvM8bEGWPijhw5kpf6AQAAAAAlXK6H8hpjgiR9KamTzWFnY0yotTYlY/m3krzW2ukXOy5DeQEAAACg9CroobxddXbSo4sl2rnGmDbGmGBJgyRtysN5AAAAAABlQF6CaW9JK899Mca0MMZMPa/NU5LmStooabW1NibPFQIAAAAASrVcT0pkrf3Ded+3Spp03rrNklrnrzQAAAAAQFmQp1l5AQAAAAAoKARTAAAAAIBTBFMAAAAAgFMEUwAAAACAU7l+j2lhMcYckbTHYQk1JB11eH4UX/w2kBN+G8gJvw3khN8GssPvAjkpbb+NhtbamtltKDbB1DVjTFxOL3tF2cZvAznht4Gc8NtATvhtIDv8LpCTsvTbYCgvAAAAAMApgikAAAAAwCmC6U9ecV0Aii1+G8gJvw3khN8GcsJvA9nhd4GclJnfBs+YAgAAAACcoscUAAAAAOAUwTSDMcZjjNlrjInN+PzSdU0AiifuFwAulzGmtjHmi4xl7h0ALsoYU8UYs8QYE2WM+cAYE1JW7hsM5c1gjGknaai19gnXtaD4MMbMltRC0ifW2qmu60HxwP0C2THG1Ja0wFrbNeM7948yzhhTTdI7kmpZa9tx78A5xpgqkt6VFCzpR0lDJc0S94wyzxjzoKSd1tpoY8wsSQclVSgL9w16TH/SUdIAY8xaY8xsY4zHdUFwyxgzWFKwtfYGSVcZY5q4rgnFBvcLZJERQN6UVCHjO/cPSFJAZwPHiYzv3DtwzghJL1hrb5J0SNIwcc+AJGvty9ba6IyvNSWlqYzcN8psMDXG/OtnXeKxOvsfPtJae70kr6R+TgtEcRAh6b2M5ShJXdyVgmJmnbhfIKvzA0iEuH+UedbaE9bapJ+t4t4BSdmGj5HinoGfMcbcIKmapGiVkftGqU3cl2KtHfPz78aYUGttSsbXOEn8pQoVJB3IWD4uqZ3DWlC8fM39Aj9nrT0hScaYc6u4fyA73DuQxc/Cx25xz0AGY0y4pBclDZF0qKzcN8psj2k25hpj2hhjgiUNkrTJcT1w75SkchnLFcX/X/AT7he4FO4fyA73DmT6Wfj4lbhnIIMxJkTSfEkTrLV7VIbuG/zof/KUpLmSNkpaba2NcVsOioH1+mkoTRud/WsmIHG/wKVx/0B2uHdAUrbhg3sGzvm1zvaYT8x43HCLysh9g1l5gRwYYypL+kLSMkl9JXU871khAMjCGBNrrY3g/gHgYowxD0h6Rj/1fs2RNFbcM1CGEUyBi8iYabOXpJXW2kOu6wFQcnD/AJAb3DNQ1hFMAQAAAABO8YwpAAAAAMApgikAAAAAwCmCKQAAAADAKYIpAAAAAMApgikAAAAAwKn/D9DGOF8TPQK8AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"有噪音, bert前\")\n",
    "embeddings = (embeddings_outputs['embedding_output'] + noise)[0][1:56].detach().numpy()\n",
    "token_embeddings_visualise(embeddings, text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有噪音，bert后\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x648 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"有噪音，bert后\")\n",
    "embeddings_outputs['embedding_output'] = embeddings_outputs['embedding_output'] + noise\n",
    "embeddings = bert.post_forward(**embeddings_outputs)['last_hidden_state'][0][1:56].detach().numpy()\n",
    "token_embeddings_visualise(embeddings, text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         [1.1543, 1.2970, 0.7757,  ..., 1.5602, 0.1108, 1.1854],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         ...,\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}